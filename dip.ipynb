{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155892f8-a398-4d5f-b275-b164d220b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from model import UNet\n",
    "from metrics import Metrics\n",
    "import torch.functional as F\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33961efd-14c1-4b02-9201-ef930a183467",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96130dc1-b3d3-4265-b316-56475b071ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DIP:\n",
    "    def __init__(\n",
    "        self, \n",
    "        low_res: torch.Tensor, \n",
    "        high_res: torch.Tensor,\n",
    "        input: torch.Tensor,\n",
    "        reg_noise_std: float, \n",
    "        num_iterations: int,\n",
    "        criterion: nn.MSELoss,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        device: torch.device,\n",
    "        metrics: Metrics,\n",
    "        model: nn.Module,\n",
    "        summary_writer: SummaryWriter,\n",
    "    ):\n",
    "        self.low_res = low_res\n",
    "        self.low_res_size = self.low_res.shape[-1]\n",
    "        self.high_res = high_res.unsqueeze(0)\n",
    "        self.input = input\n",
    "        self.reg_noise_std = 0.05\n",
    "        self.num_iterations = num_iterations\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.metrics = metrics\n",
    "        self.model = model\n",
    "        self.summary_writer = summary_writer\n",
    "        self.step = 0\n",
    "        self.history = []\n",
    "    \n",
    "    def closure(self, input_saved: torch.Tensor, noise: torch.Tensor):        \n",
    "        if self.reg_noise_std > 0:\n",
    "            self.input = input_saved + (noise.normal_() * self.reg_noise_std)\n",
    "    \n",
    "        self.input = self.input.to(self.device)\n",
    "        self.low_res = self.low_res.to(self.device)\n",
    "        \n",
    "        output_hr = self.model(self.input)\n",
    "        output_lr = downsample(output_hr, (self.low_res_size, self.low_res_size))\n",
    "        \n",
    "        loss = self.criterion(output_lr, self.low_res)\n",
    "        loss.backward()\n",
    "\n",
    "        if self.step <= 100 and self.step % 10 == 0 or \\\n",
    "           self.step % 100 == 0 or \\\n",
    "           self.step == self.num_iterations-1:\n",
    "        \n",
    "            mse, psnr, ssim, lpips = self.evaluate(output_hr)     \n",
    "            print(f\"{self.step} Loss: {loss} MSE: {mse} PSNR: {psnr} SSIM: {ssim} LPIPS: {lpips}\")\n",
    "            self.log(loss, mse, psnr, ssim, lpips, self.step)\n",
    "            if self.step == self.num_iterations-1:\n",
    "                self.mse = mse\n",
    "                self.psnr = psnr\n",
    "                self.ssim = ssim\n",
    "                self.lpips = lpips\n",
    "            \n",
    "            output_hr_numpy = output_hr.squeeze(0).permute(1,2,0).cpu().detach().numpy()\n",
    "            plt.imshow(output_hr_numpy)\n",
    "            plt.show()\n",
    "            self.history.append(output_hr_numpy)\n",
    "        self.step += 1\n",
    "\n",
    "    def train(self, input: torch.Tensor) -> (float, float, float, float) :\n",
    "        input_saved = input.detach().clone()\n",
    "        noise = input.detach().clone()\n",
    "        \n",
    "        for i in range(self.num_iterations):\n",
    "            self.optimizer.zero_grad()\n",
    "            self.closure(input_saved, noise)\n",
    "            self.optimizer.step()\n",
    "\n",
    "        return self.mse, self.psnr, self.ssim, self.lpips\n",
    "\n",
    "    def evaluate(self, prediction):\n",
    "        prediction = prediction.to(self.device)\n",
    "        self.high_res = self.high_res.to(self.device)\n",
    "        mse = self.metrics.calculate_mse(prediction, self.high_res)\n",
    "        psnr = self.metrics.calculate_psnr(prediction, self.high_res)\n",
    "        ssim = self.metrics.calculate_ssim(prediction, self.high_res)\n",
    "        lpips = self.metrics.calculate_lpips(prediction, self.high_res)\n",
    "        return mse, psnr, ssim, lpips\n",
    "\n",
    "    def log(self, loss, mse, psnr, ssim, lpips, step):\n",
    "        self.summary_writer.add_scalars(\n",
    "            \"loss\",\n",
    "            {\"train\": float(loss)},\n",
    "            self.step\n",
    "        )\n",
    "        self.summary_writer.add_scalars(\n",
    "            \"mse\",\n",
    "            {\"train\": float(mse)},\n",
    "            self.step\n",
    "        )\n",
    "        self.summary_writer.add_scalars(\n",
    "            \"psnr\",\n",
    "            {\"train\": float(psnr)},     \n",
    "            self.step\n",
    "        )\n",
    "        self.summary_writer.add_scalars(\n",
    "            \"ssim\",\n",
    "            {\"train\": float(ssim)},\n",
    "            self.step\n",
    "        )\n",
    "        self.summary_writer.add_scalars(\n",
    "            \"lpips\",\n",
    "            {\"train\": float(lpips)},\n",
    "            self.step\n",
    "        )\n",
    "\n",
    "    def get_history(self) -> np.ndarray:\n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0556ca-8168-4272-af51-af31946e5492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(image: torch.Tensor, size: (int, int)):\n",
    "    transform = transforms.Resize(size, interpolation=transforms.InterpolationMode.BICUBIC)\n",
    "    return transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee77fa7b-2d2e-440f-9565-c52c623cf017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_tensor(tensor: torch.Tensor):\n",
    "    tensor = tensor.permute(1,2,0).detach().cpu().numpy()\n",
    "    tensor = (tensor - np.min(tensor)) / (np.max(tensor) - np.min(tensor))\n",
    "    plt.imshow(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb10c541-d7da-479d-9aa8-bca030275bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_norm(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    tensor = (tensor - tensor.min()) / (tensor.max() - tensor.min())\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328b26a5-6b25-4512-820d-05755739f401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(low_res: torch.Tensor, high_res: torch.Tensor, id: int, num_iterations: int, reg_noise_std: float, histories, log_id: str):\n",
    "    input = torch.randn_like(high_res).unsqueeze(0)\n",
    "    input *= 0.1\n",
    "    \n",
    "    model = UNet(input_channels=3, output_channels=3)\n",
    "    model = model.to(DEVICE)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    metrics = Metrics()\n",
    "    \n",
    "    log_dir = \"./logs\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_path = f\"{log_dir}/run_{log_id}/{id}\" \n",
    "    print(f\"Writing logs to {log_path}\")\n",
    "    summary_writer = SummaryWriter(\n",
    "        str(log_path),\n",
    "        flush_secs=5,\n",
    "    )\n",
    "\n",
    "    dip = DIP(\n",
    "        low_res = low_res, \n",
    "        high_res = high_res,\n",
    "        input = input,\n",
    "        reg_noise_std = reg_noise_std, \n",
    "        num_iterations = num_iterations,\n",
    "        criterion = criterion,\n",
    "        optimizer = optimizer,\n",
    "        device = DEVICE,\n",
    "        metrics = metrics,\n",
    "        model = model,\n",
    "        summary_writer = summary_writer,      \n",
    "    )\n",
    "\n",
    "    histories[id] = dip.get_history()\n",
    "\n",
    "    return dip.train(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4ec3dc-1d04-46d6-b458-dea3d8f56835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history: [np.ndarray]):\n",
    "    m, n = 4, 5\n",
    "    fig, axes = plt.subplots(m, n)\n",
    "    for j in range(m):\n",
    "        for i in range(n):\n",
    "            if m == 1:\n",
    "                axes[i].imshow(history[i])\n",
    "                axes[i].axis(\"off\")\n",
    "            else:\n",
    "                axes[j][i].imshow(history[j*n + i])\n",
    "                axes[j][i].axis(\"off\")\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5666e7a-1547-4597-96f1-cac7c705c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_LEVEL = 0\n",
    "DOWN_FACTOR = 8\n",
    "LOOPS = 1\n",
    "lr_input_dir = f\"./input/noise_{NOISE_LEVEL}_down_{DOWN_FACTOR}\"\n",
    "hr_input_dir = f\"./input/original_high\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64fcc45-2bf7-4150-b9aa-3fa871d5a33e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_indices = [(0,1), (1,0), (1,3), (3,7)]\n",
    "overall_histories = {}\n",
    "time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "total_mse = 0\n",
    "total_psnr = 0\n",
    "total_ssim = 0\n",
    "total_lpips = 0\n",
    "for j in range(LOOPS):\n",
    "    overall_histories[j] = {}\n",
    "    histories = overall_histories[j]\n",
    "    for i, indices in enumerate(image_indices):\n",
    "        low_res = Image.open(f\"{lr_input_dir}/original_low-{indices[0]}-{indices[1]}.jpg\")\n",
    "        high_res = Image.open(f\"{hr_input_dir}/original_high-{indices[0]}-{indices[1]}.jpg\")\n",
    "        \n",
    "        low_res = transforms.ToTensor()(low_res)\n",
    "        low_res = min_max_norm(low_res)\n",
    "        assert (low_res.shape[-1] % 8 == 0)\n",
    "        down_scale_size = low_res.shape[-1] // 8\n",
    "        low_res = downsample(low_res, (down_scale_size, down_scale_size))\n",
    "    \n",
    "        high_res = transforms.ToTensor()(high_res)\n",
    "        high_res = min_max_norm(high_res)\n",
    "        \n",
    "        mse, psnr, ssim, lpips = main(\n",
    "            low_res=low_res, \n",
    "            high_res=high_res, \n",
    "            id=i,\n",
    "            num_iterations = 1000,\n",
    "            reg_noise_std = 0.05,\n",
    "            histories = histories,\n",
    "            log_id = time, \n",
    "        )\n",
    "        total_mse += mse\n",
    "        total_psnr += psnr\n",
    "        total_ssim += ssim\n",
    "        total_lpips += lpips\n",
    "avg_mse = total_mse / len(image_indices) / LOOPS\n",
    "avg_psnr = total_psnr / len(image_indices) / LOOPS\n",
    "avg_ssim = total_ssim / len(image_indices) / LOOPS\n",
    "avg_lpips = total_lpips / len(image_indices) / LOOPS\n",
    "print(f\"Test Evaluaton: Avg MSE: {avg_mse} Avg PSNR {avg_psnr} Avg SSIM {avg_ssim} Avg LPIPS {avg_lpips}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02921c2f-d741-424f-9192-2da47b790af9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = overall_histories[0][0]\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1633ada1-a3b6-4f73-a96c-723ceccd7cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "output_dir = f\"./output/noise_{NOISE_LEVEL}_down_{DOWN_FACTOR}\"\n",
    "os.makedirs(output_dir, exist_ok = True)\n",
    "\n",
    "def save_images(histories):\n",
    "    fig, axes = plt.subplots(LOOPS,len(image_indices))\n",
    "    for j in range(LOOPS):\n",
    "        for i in range(len(image_indices)):\n",
    "            history = overall_histories[j][i]\n",
    "            output_path = f\"{output_dir}/output_{i}.jpg\"\n",
    "            image = history[-1]\n",
    "            axes[j][i].imshow(image)\n",
    "            axes[j][i].axis(\"off\")\n",
    "    \n",
    "            image = 255 * (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "            image = image.astype('uint8')\n",
    "            image = Image.fromarray(image)\n",
    "            #image.save(output_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881a986f-75b2-4105-ade0-86b5aec5f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_images(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce64bb4-ddb9-4e91-958f-587bdee935a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
